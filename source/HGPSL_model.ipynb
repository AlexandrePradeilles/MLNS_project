{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl\n",
    "dgl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_HGPLS import net_graph, train, test, extract_prediction\n",
    "from graph_networks import HGPSLModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/SMILES_tokenized_PubChem_shard00_160k\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"seyonec/SMILES_tokenized_PubChem_shard00_160k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "atoms = [\"\", \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\"]\n",
    "print(len(atoms))\n",
    "ids = tokenizer(atoms).input_ids\n",
    "\n",
    "toks = list()\n",
    "for i in ids:\n",
    "    if len(i) >= 3:\n",
    "        toks.append(i[1])\n",
    "    else:\n",
    "        toks.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels_g = dgl.load_graphs(\"../data/HIV_dgl_graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_g = labels_g['glabel'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = torch.zeros((len(toks), 1))\n",
    "for i in range(len(toks)):\n",
    "    tok[i] = toks[i]\n",
    "\n",
    "tok\n",
    "transfo_atoms = model(tok.to(torch.long)).logits.reshape(100, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, random_state=42)\n",
    "res = pca.fit_transform(transfo_atoms.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2443/2443 [00:02<00:00, 886.42it/s]\n"
     ]
    }
   ],
   "source": [
    "new_dataset = list()\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    g= dataset[i]\n",
    "    l = labels_g[i]\n",
    "    ids=list(g.ndata[\"atomic\"].numpy().flatten().astype(int))\n",
    "    g.ndata[\"feature\"] = torch.tensor(res[ids])\n",
    "    g.edata[\"type\"] = g.edata[\"type\"].to(dtype=torch.float32)\n",
    "    g = dgl.add_self_loop(g)\n",
    "    g = dgl.add_reverse_edges(g, copy_edata=True)\n",
    "    a=dgl.graph(g.edges(), idtype=torch.int64)\n",
    "    a.ndata[\"feature\"] = g.ndata[\"feature\"]\n",
    "    a.edata[\"type\"] = g.edata[\"type\"].flatten()\n",
    "    new_dataset.append((a, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(new_dataset, test_size=0.25, random_state=42)\n",
    "\n",
    "train_dataloader = GraphDataLoader(train_dataset, batch_size=16, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(test_dataset, batch_size=16, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture\n",
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "model = HGPSLModel(in_feat=100, out_feat=3, hid_feat=256).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.0001, #weight_decay=0.001\n",
    "    )\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:22<00:00,  5.11it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.3761, train_acc=0.4154, val_acc=0.4403, vall_loss=1.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:23<00:00,  4.84it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=1.1276, train_acc=0.4061, val_acc=0.4845, vall_loss=1.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.46it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=1.0977, train_acc=0.4334, val_acc=0.4975, vall_loss=0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:28<00:00,  4.06it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=1.0922, train_acc=0.4345, val_acc=0.4795, vall_loss=0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:28<00:00,  4.10it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=1.0753, train_acc=0.4350, val_acc=0.4877, vall_loss=0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:28<00:00,  4.10it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=1.0699, train_acc=0.4367, val_acc=0.4845, vall_loss=0.9671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:33<00:00,  3.44it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=1.0624, train_acc=0.4498, val_acc=0.4730, vall_loss=0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:36<00:00,  3.14it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=1.0590, train_acc=0.4443, val_acc=0.5155, vall_loss=0.9550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:36<00:00,  3.14it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=1.0703, train_acc=0.4410, val_acc=0.4468, vall_loss=1.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:36<00:00,  3.18it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=1.0601, train_acc=0.4569, val_acc=0.4763, vall_loss=0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:29<00:00,  3.90it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss=1.0419, train_acc=0.4520, val_acc=0.4730, vall_loss=0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:29<00:00,  3.93it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss=1.0361, train_acc=0.4525, val_acc=0.4975, vall_loss=0.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:31<00:00,  3.59it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss=1.0258, train_acc=0.4574, val_acc=0.4812, vall_loss=0.9753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:37<00:00,  3.06it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss=1.0106, train_acc=0.4722, val_acc=0.4975, vall_loss=0.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:38<00:00,  3.02it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss=1.0187, train_acc=0.4694, val_acc=0.5090, vall_loss=0.9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:37<00:00,  3.04it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss=1.0249, train_acc=0.4672, val_acc=0.4894, vall_loss=0.9640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:37<00:00,  3.05it/s]\n",
      "100%|██████████| 39/39 [00:07<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss=1.0088, train_acc=0.4793, val_acc=0.5106, vall_loss=0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:34<00:00,  3.34it/s]\n",
      "100%|██████████| 39/39 [00:05<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch 8, final test acc 0.5155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model and keep the best validation loss model\n",
    "bad_cound = 0\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "epochs = 20\n",
    "patience = 20\n",
    "print_every = 1\n",
    "train_times = []\n",
    "for e in range(epochs):\n",
    "    s_time = time()\n",
    "    train_loss, train_acc = train(model, optimizer, loss, train_dataloader, device, True)\n",
    "    train_times.append(time() - s_time)\n",
    "    val_acc, val_loss = test(model, loss, test_dataloader, device, True)\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        bad_cound = 0\n",
    "        best_epoch = e + 1\n",
    "        torch.save(model.state_dict(), \"../models/HGPSLModel_prot.pt\")\n",
    "    else:\n",
    "        bad_cound += 1\n",
    "    if bad_cound >= patience:\n",
    "        break\n",
    "\n",
    "    if (e + 1) % print_every == 0:\n",
    "        log_format = (\n",
    "            \"Epoch {}: train_loss={:.4f}, train_acc={:.4f}, val_acc={:.4f}, vall_loss={:.4f}\"\n",
    "        )\n",
    "        print(log_format.format(e + 1, train_loss, train_acc, val_acc, val_loss))\n",
    "print(\n",
    "    \"Best Epoch {}, final test acc {:.4f}\".format(\n",
    "        best_epoch, best_val_acc\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../models/HGPSLModel_prot.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract last hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:04<00:00,  8.01it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_test=[]\n",
    "lab_test = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "        batch_graphs, batch_labels = batch\n",
    "        batch_graphs = batch_graphs.to(device)\n",
    "        batch_labels = batch_labels.long().to(device)\n",
    "        out = model(batch_graphs, batch_graphs.ndata[\"feature\"].to(dtype=torch.float32))\n",
    "        out=model.readout\n",
    "        emb_test += out.tolist()\n",
    "        lab_test += batch_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:16<00:00,  7.07it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_train=[]\n",
    "lab_train = []\n",
    "for batch in tqdm(train_dataloader):\n",
    "        batch_graphs, batch_labels = batch\n",
    "        batch_graphs = batch_graphs.to(device)\n",
    "        batch_labels = batch_labels.long().to(device)\n",
    "        out = model(batch_graphs, batch_graphs.ndata[\"feature\"].to(dtype=torch.float32))\n",
    "        out=model.readout\n",
    "        emb_train += out.tolist()\n",
    "        lab_train += batch_labels.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb =XGBClassifier(random_state=0)\n",
    "\n",
    "xgb.fit(emb_train, lab_train)\n",
    "predxgb = xgb.predict(emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6072013093289689, 0.6211857504339401)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "accuracy_score(lab_test, predxgb), f1_score(lab_test, predxgb, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[161,  95,   5],\n",
       "       [ 86, 150,  19],\n",
       "       [  9,  26,  60]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(lab_test, predxgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
