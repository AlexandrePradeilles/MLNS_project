{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functions_HGPLS import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.FakeNewsDataset('gossipcop', 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = list()\n",
    "for i in range(len(dataset)):\n",
    "    g, l = dataset[i]\n",
    "    g.ndata[\"feature\"] = torch.ones_like(dataset.feature[g.ndata[\"_ID\"]])\n",
    "    # g.ndata[\"feature\"] = g.ndata[\"attr\"]\n",
    "    g = dgl.add_self_loop(g)\n",
    "    g = dgl.add_reverse_edges(g)\n",
    "    new_dataset.append((g, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(new_dataset, test_size=0.25, random_state=42)\n",
    "\n",
    "train_dataloader = GraphDataLoader(train_dataset, batch_size=16, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(test_dataset, batch_size=16, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GATConv\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, n_classes):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = GATConv(in_feats, h_feats, num_heads=4)\n",
    "        self.layer2 = GATConv(4*h_feats, h_feats, num_heads=4)\n",
    "        self.layer3 = GATConv(4*h_feats, h_feats, num_heads=6)\n",
    "        self.fc = nn.Linear(h_feats, n_classes)\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        x1 = self.layer1(g, in_feat)\n",
    "        x1 = self.elu(x1)\n",
    "        x1 = x1.view(in_feat.shape[0], -1)\n",
    "        x2 = self.layer2(g, x1)\n",
    "        x2 = self.elu(x2)\n",
    "        x2 = x2.view(in_feat.shape[0], -1)\n",
    "        x3 = self.layer3(g, x2)\n",
    "        x3 = torch.mean(x3, dim=1)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = x3\n",
    "            x4 = dgl.readout_nodes(g, 'h')\n",
    "        return F.log_softmax(self.fc(x4), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture\n",
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "model = GAT(in_feats=768, n_classes=2, h_feats=128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.001, weight_decay=0.001\n",
    "    )\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:37<00:00,  6.86it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=8.8670, train_acc=0.4980, val_acc=0.5329, vall_loss=0.9505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:29<00:00,  8.61it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 20.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=1.2711, train_acc=0.5554, val_acc=0.6164, vall_loss=0.7304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:35<00:00,  7.19it/s]\n",
      "100%|██████████| 86/86 [00:05<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.7757, train_acc=0.6362, val_acc=0.7592, vall_loss=0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:35<00:00,  7.30it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.6818, train_acc=0.6798, val_acc=0.7313, vall_loss=0.6357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:34<00:00,  7.35it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.6715, train_acc=0.6811, val_acc=0.7313, vall_loss=0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:34<00:00,  7.36it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.6387, train_acc=0.6986, val_acc=0.7635, vall_loss=0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:34<00:00,  7.37it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.6281, train_acc=0.7106, val_acc=0.7694, vall_loss=0.5894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:35<00:00,  7.33it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.6263, train_acc=0.7013, val_acc=0.7701, vall_loss=0.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:35<00:00,  7.15it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.6172, train_acc=0.7077, val_acc=0.7687, vall_loss=0.5945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:34<00:00,  7.37it/s]\n",
      "100%|██████████| 86/86 [00:04<00:00, 17.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.6539, train_acc=0.6901, val_acc=0.7723, vall_loss=0.5861\n",
      "Best Epoch 10, final test acc 0.5861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model and keep the best validation loss model\n",
    "bad_cound = 0\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "epochs = 10\n",
    "patience = 10\n",
    "print_every = 1\n",
    "train_times = []\n",
    "for e in range(epochs):\n",
    "    s_time = time()\n",
    "    train_loss, train_acc = train(model, optimizer, loss, train_dataloader, device)\n",
    "    train_times.append(time() - s_time)\n",
    "    val_acc, val_loss = test(model, loss, test_dataloader, device)\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_loss = val_loss\n",
    "        bad_cound = 0\n",
    "        best_epoch = e + 1\n",
    "        torch.save(model.state_dict(), \"../models/GATModel_prot.pt\")\n",
    "    else:\n",
    "        bad_cound += 1\n",
    "    if bad_cound >= patience:\n",
    "        break\n",
    "\n",
    "    if (e + 1) % print_every == 0:\n",
    "        log_format = (\n",
    "            \"Epoch {}: train_loss={:.4f}, train_acc={:.4f}, val_acc={:.4f}, vall_loss={:.4f}\"\n",
    "        )\n",
    "        print(log_format.format(e + 1, train_loss, train_acc, val_acc, val_loss))\n",
    "print(\n",
    "    \"Best Epoch {}, final test acc {:.4f}\".format(\n",
    "        best_epoch, best_val_loss\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
