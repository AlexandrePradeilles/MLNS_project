{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from torch) (3.10.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement dgl.sparse (from versions: none)\n",
      "ERROR: No matching distribution found for dgl.sparse\n"
     ]
    }
   ],
   "source": [
    "pip install dgl.sparse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl==0.9Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading dgl-0.9.0-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "     ---------------------------------------- 2.8/2.8 MB 22.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from dgl==0.9) (4.65.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from dgl==0.9) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from dgl==0.9) (1.24.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from dgl==0.9) (5.9.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from dgl==0.9) (2.28.1)\n",
      "Requirement already satisfied: networkx>=2.1 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from dgl==0.9) (2.8.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from requests>=2.19.0->dgl==0.9) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from requests>=2.19.0->dgl==0.9) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from requests>=2.19.0->dgl==0.9) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from requests>=2.19.0->dgl==0.9) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenaa\\appdata\\local\\continuum\\miniconda3\\envs\\dl_segmentation\\lib\\site-packages (from tqdm->dgl==0.9) (0.4.6)\n",
      "Installing collected packages: dgl\n",
      "  Attempting uninstall: dgl\n",
      "    Found existing installation: dgl 1.0.1\n",
      "    Uninstalling dgl-1.0.1:\n",
      "      Successfully uninstalled dgl-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'C:\\\\Users\\\\lenaa\\\\AppData\\\\Local\\\\Continuum\\\\miniconda3\\\\envs\\\\DL_segmentation\\\\Lib\\\\site-packages\\\\~gl\\\\dgl.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install dgl==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functions_HGPLS import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.FakeNewsDataset('gossipcop', 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.GINDataset(\"PROTEINS\", self_loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = dgl.load_graphs(\"../data/HIV_dgl_graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels['glabel'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atomic': tensor([[8.],\n",
       "        [8.],\n",
       "        [6.],\n",
       "        [6.],\n",
       "        [6.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [6.],\n",
       "        [6.]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5].ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = list()\n",
    "for i in range(len(dataset)):\n",
    "    #g, l = dataset[i]\n",
    "    g = dataset[i]\n",
    "    l = labels[i]\n",
    "    #g.ndata[\"feature\"] = torch.ones_like(dataset.feature[g.ndata[\"_ID\"]])\n",
    "    g.ndata[\"feature\"] = g.ndata[\"atomic\"]\n",
    "    g = dgl.add_self_loop(g)\n",
    "    g = dgl.add_reverse_edges(g)\n",
    "    new_dataset.append((g, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(new_dataset, test_size=0.25, random_state=42)\n",
    "\n",
    "train_dataloader = GraphDataLoader(train_dataset, batch_size=16, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(test_dataset, batch_size=16, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GATConv\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, n_classes):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = GATConv(in_feats, h_feats, num_heads=4)\n",
    "        self.layer2 = GATConv(4*h_feats, h_feats, num_heads=4)\n",
    "        self.layer3 = GATConv(4*h_feats, h_feats, num_heads=6)\n",
    "        self.fc = nn.Linear(h_feats, n_classes)\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        x1 = self.layer1(g, in_feat)\n",
    "        x1 = self.elu(x1)\n",
    "        x1 = x1.view(in_feat.shape[0], -1)\n",
    "        x2 = self.layer2(g, x1)\n",
    "        x2 = self.elu(x2)\n",
    "        x2 = x2.view(in_feat.shape[0], -1)\n",
    "        x3 = self.layer3(g, x2)\n",
    "        x3 = torch.mean(x3, dim=1)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = x3\n",
    "            x4 = dgl.readout_nodes(g, 'h')\n",
    "        return F.log_softmax(self.fc(x4), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture\n",
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "model = GAT(in_feats=1, n_classes=3, h_feats=128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.00001, weight_decay=0.0001\n",
    "    )\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/115 [00:00<?, ?it/s]c:\\Users\\lenaa\\AppData\\Local\\Continuum\\miniconda3\\envs\\DL_segmentation\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n",
      "100%|██████████| 115/115 [00:17<00:00,  6.45it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.0838, train_acc=0.4247, val_acc=0.4746, vall_loss=1.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:17<00:00,  6.48it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 14.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=1.0785, train_acc=0.4230, val_acc=0.4664, vall_loss=1.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:17<00:00,  6.74it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=1.0780, train_acc=0.4241, val_acc=0.4746, vall_loss=1.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:17<00:00,  6.57it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=1.0777, train_acc=0.4274, val_acc=0.4763, vall_loss=1.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:17<00:00,  6.71it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 16.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=1.0774, train_acc=0.4279, val_acc=0.4746, vall_loss=1.0535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:17<00:00,  6.60it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=1.0771, train_acc=0.4274, val_acc=0.4730, vall_loss=1.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:18<00:00,  6.29it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=1.0769, train_acc=0.4274, val_acc=0.4697, vall_loss=1.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:17<00:00,  6.52it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=1.0767, train_acc=0.4279, val_acc=0.4714, vall_loss=1.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 30/115 [00:06<00:17,  4.81it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1837056 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lenaa\\Desktop\\3A Centrale\\2e trimestre\\MLNS\\projet-groupe\\MLNS_project\\source\\GAT.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenaa/Desktop/3A%20Centrale/2e%20trimestre/MLNS/projet-groupe/MLNS_project/source/GAT.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenaa/Desktop/3A%20Centrale/2e%20trimestre/MLNS/projet-groupe/MLNS_project/source/GAT.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     s_time \u001b[39m=\u001b[39m time()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lenaa/Desktop/3A%20Centrale/2e%20trimestre/MLNS/projet-groupe/MLNS_project/source/GAT.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(model, optimizer, loss, train_dataloader, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenaa/Desktop/3A%20Centrale/2e%20trimestre/MLNS/projet-groupe/MLNS_project/source/GAT.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train_times\u001b[39m.\u001b[39mappend(time() \u001b[39m-\u001b[39m s_time)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lenaa/Desktop/3A%20Centrale/2e%20trimestre/MLNS/projet-groupe/MLNS_project/source/GAT.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     val_acc, val_loss \u001b[39m=\u001b[39m test(model, loss, test_dataloader, device)\n",
      "File \u001b[1;32mc:\\Users\\lenaa\\Desktop\\3A Centrale\\2e trimestre\\MLNS\\projet-groupe\\MLNS_project\\source\\functions_HGPLS.py:370\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loss_metric, trainloader, device)\u001b[0m\n\u001b[0;32m    368\u001b[0m out \u001b[39m=\u001b[39m model(batch_graphs, batch_graphs\u001b[39m.\u001b[39mndata[\u001b[39m\"\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32))\n\u001b[0;32m    369\u001b[0m loss \u001b[39m=\u001b[39m loss_metric(out, batch_labels)\n\u001b[1;32m--> 370\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    371\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    373\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\lenaa\\AppData\\Local\\Continuum\\miniconda3\\envs\\DL_segmentation\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lenaa\\AppData\\Local\\Continuum\\miniconda3\\envs\\DL_segmentation\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1837056 bytes."
     ]
    }
   ],
   "source": [
    "# Train model and keep the best validation loss model\n",
    "bad_cound = 0\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "epochs = 10\n",
    "patience = 10\n",
    "print_every = 1\n",
    "train_times = []\n",
    "for e in range(epochs):\n",
    "    s_time = time()\n",
    "    train_loss, train_acc = train(model, optimizer, loss, train_dataloader, device)\n",
    "    train_times.append(time() - s_time)\n",
    "    val_acc, val_loss = test(model, loss, test_dataloader, device)\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_loss = val_loss\n",
    "        bad_cound = 0\n",
    "        best_epoch = e + 1\n",
    "        torch.save(model.state_dict(), \"models/GATModel_prot.pt\")\n",
    "    else:\n",
    "        bad_cound += 1\n",
    "    if bad_cound >= patience:\n",
    "        break\n",
    "\n",
    "    if (e + 1) % print_every == 0:\n",
    "        log_format = (\n",
    "            \"Epoch {}: train_loss={:.4f}, train_acc={:.4f}, val_acc={:.4f}, vall_loss={:.4f}\"\n",
    "        )\n",
    "        print(log_format.format(e + 1, train_loss, train_acc, val_acc, val_loss))\n",
    "print(\n",
    "    \"Best Epoch {}, final test loss {:.4f}\".format(\n",
    "        best_epoch, best_val_loss\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]c:\\Users\\lenaa\\AppData\\Local\\Continuum\\miniconda3\\envs\\DL_segmentation\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n",
      "100%|██████████| 39/39 [00:02<00:00, 13.17it/s]\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "lab = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "        batch_graphs, batch_labels = batch\n",
    "        batch_graphs = batch_graphs.to(device)\n",
    "        batch_labels = batch_labels.long().to(device)\n",
    "        out = model(batch_graphs, batch_graphs.ndata[\"feature\"].to(dtype=torch.float32))\n",
    "        pred += out.argmax(dim=1).tolist()\n",
    "        lab += batch_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151, 105,   5],\n",
       "       [110, 144,   1],\n",
       "       [ 27,  68,   0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(lab, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
