{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dgl.sparse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dgl==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.decomposition import PCA\n",
    "import networkx as nx\n",
    "\n",
    "from functions_HGPLS import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/SMILES_tokenized_PubChem_shard00_160k\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"seyonec/SMILES_tokenized_PubChem_shard00_160k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "atoms = [\"\", \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\", \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\"]\n",
    "print(len(atoms))\n",
    "ids = tokenizer(atoms).input_ids\n",
    "\n",
    "toks = list()\n",
    "for i in ids:\n",
    "    if len(i) >= 3:\n",
    "        toks.append(i[1])\n",
    "    else:\n",
    "        toks.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = dgl.load_graphs(\"../data/HIV_dgl_graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels['glabel'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dataset[0].ndata[\"atomic\"]\n",
    "tok = torch.zeros((len(toks), 1))\n",
    "for i in range(len(toks)):\n",
    "    tok[i] = toks[i]\n",
    "\n",
    "tok\n",
    "transfo_atoms = model(tok.to(torch.long)).logits.reshape(100, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, random_state=42)\n",
    "res = pca.fit_transform(transfo_atoms.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = list()\n",
    "for i in range(len(dataset)):\n",
    "    #g, l = dataset[i]\n",
    "    g = dataset[i]\n",
    "    l = labels[i]\n",
    "    #g.ndata[\"feature\"] = torch.ones_like(dataset.feature[g.ndata[\"_ID\"]])\n",
    "    ids=list(g.ndata[\"atomic\"].numpy().flatten().astype(int))\n",
    "    g.ndata[\"feature\"] = torch.tensor(res[ids]) #g.ndata[\"atomic\"]\n",
    "    g = dgl.add_self_loop(g)\n",
    "    g = dgl.add_reverse_edges(g)\n",
    "    new_dataset.append((g, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(new_dataset, test_size=0.25, random_state=42)\n",
    "\n",
    "train_dataloader = GraphDataLoader(train_dataset, batch_size=16, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(test_dataset, batch_size=16, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GATConv\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, n_classes):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = GATConv(in_feats, h_feats, num_heads=4)\n",
    "        self.layer2 = GATConv(4*h_feats, h_feats, num_heads=4)\n",
    "        self.layer3 = GATConv(4*h_feats, h_feats, num_heads=6)\n",
    "        self.fc = nn.Linear(h_feats, n_classes)\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        x1 = self.layer1(g, in_feat)\n",
    "        x1 = self.elu(x1)\n",
    "        x1 = x1.view(in_feat.shape[0], -1)\n",
    "        x2 = self.layer2(g, x1)\n",
    "        x2 = self.elu(x2)\n",
    "        x2 = x2.view(in_feat.shape[0], -1)\n",
    "        x3 = self.layer3(g, x2)\n",
    "        x3 = torch.mean(x3, dim=1)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = x3\n",
    "            x4 = dgl.readout_nodes(g, 'h')\n",
    "        self.hidden = x4\n",
    "        return F.log_softmax(self.fc(x4), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture\n",
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "model = GAT(in_feats=100, n_classes=3, h_feats=256).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.000002 #, weight_decay=0.0001\n",
    "    )\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:19<00:00,  5.83it/s]\n",
      "100%|██████████| 39/39 [00:01<00:00, 19.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=62.1915, train_acc=0.3876, val_acc=0.4255, vall_loss=6.7287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:15<00:00,  7.21it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=6.3449, train_acc=0.3750, val_acc=0.3650, vall_loss=4.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:18<00:00,  6.20it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=3.8966, train_acc=0.3881, val_acc=0.3928, vall_loss=3.1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:18<00:00,  6.09it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=2.9235, train_acc=0.3979, val_acc=0.4648, vall_loss=2.4346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.45it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=2.5616, train_acc=0.4078, val_acc=0.4632, vall_loss=2.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:26<00:00,  4.33it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=2.4541, train_acc=0.4007, val_acc=0.4484, vall_loss=2.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.58it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=2.3391, train_acc=0.3996, val_acc=0.4664, vall_loss=1.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.56it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=2.1957, train_acc=0.3985, val_acc=0.4484, vall_loss=1.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.56it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=2.1086, train_acc=0.4083, val_acc=0.4534, vall_loss=1.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:20<00:00,  5.50it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=2.0569, train_acc=0.4105, val_acc=0.4534, vall_loss=1.8053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:18<00:00,  6.24it/s]\n",
      "100%|██████████| 39/39 [00:02<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss=2.0113, train_acc=0.4192, val_acc=0.4337, vall_loss=1.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:19<00:00,  5.76it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss=1.9673, train_acc=0.4159, val_acc=0.4321, vall_loss=1.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.69it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss=1.8962, train_acc=0.4181, val_acc=0.4255, vall_loss=1.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.58it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss=1.8342, train_acc=0.4056, val_acc=0.4239, vall_loss=1.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.66it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss=1.7756, train_acc=0.4165, val_acc=0.4206, vall_loss=1.8510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.46it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss=1.7292, train_acc=0.4121, val_acc=0.4239, vall_loss=1.6098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:25<00:00,  4.57it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss=1.7228, train_acc=0.4170, val_acc=0.4304, vall_loss=1.5823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.62it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss=1.6724, train_acc=0.4219, val_acc=0.4452, vall_loss=1.4232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:23<00:00,  4.84it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss=1.6588, train_acc=0.4252, val_acc=0.4435, vall_loss=1.4295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.64it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss=1.6439, train_acc=0.4209, val_acc=0.4435, vall_loss=1.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.70it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss=1.6267, train_acc=0.4285, val_acc=0.4452, vall_loss=1.4133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.68it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss=1.6138, train_acc=0.4361, val_acc=0.4435, vall_loss=1.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:23<00:00,  4.82it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss=1.6034, train_acc=0.4361, val_acc=0.4468, vall_loss=1.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.61it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss=1.5946, train_acc=0.4367, val_acc=0.4419, vall_loss=1.3992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.67it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss=1.5870, train_acc=0.4356, val_acc=0.4354, vall_loss=1.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.68it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss=1.5797, train_acc=0.4383, val_acc=0.4370, vall_loss=1.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.70it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss=1.5731, train_acc=0.4378, val_acc=0.4354, vall_loss=1.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.64it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss=1.5667, train_acc=0.4400, val_acc=0.4321, vall_loss=1.3834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.74it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss=1.5617, train_acc=0.4389, val_acc=0.4321, vall_loss=1.3754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.77it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss=1.5590, train_acc=0.4329, val_acc=0.4337, vall_loss=1.3627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.71it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: train_loss=1.5563, train_acc=0.4356, val_acc=0.4337, vall_loss=1.3490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: train_loss=1.5512, train_acc=0.4367, val_acc=0.4354, vall_loss=1.3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.77it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: train_loss=1.5468, train_acc=0.4389, val_acc=0.4354, vall_loss=1.3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.71it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: train_loss=1.5419, train_acc=0.4394, val_acc=0.4370, vall_loss=1.3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:23<00:00,  4.79it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: train_loss=1.5372, train_acc=0.4410, val_acc=0.4370, vall_loss=1.3087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: train_loss=1.5325, train_acc=0.4454, val_acc=0.4337, vall_loss=1.3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.66it/s]\n",
      "100%|██████████| 39/39 [00:03<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Epoch 7, final test loss 0.4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model and keep the best validation loss model\n",
    "bad_cound = 0\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "epochs = 40\n",
    "patience = 30\n",
    "print_every = 1\n",
    "train_times = []\n",
    "for e in range(epochs):\n",
    "    s_time = time()\n",
    "    train_loss, train_acc = train(model, optimizer, loss, train_dataloader, device)\n",
    "    train_times.append(time() - s_time)\n",
    "    val_acc, val_loss = test(model, loss, test_dataloader, device)\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        bad_cound = 0\n",
    "        best_epoch = e + 1\n",
    "        torch.save(model.state_dict(), \"../models/GATModel_prot.pt\")\n",
    "    else:\n",
    "        bad_cound += 1\n",
    "    if bad_cound >= patience:\n",
    "        break\n",
    "\n",
    "    if (e + 1) % print_every == 0:\n",
    "        log_format = (\n",
    "            \"Epoch {}: train_loss={:.4f}, train_acc={:.4f}, val_acc={:.4f}, vall_loss={:.4f}\"\n",
    "        )\n",
    "        print(log_format.format(e + 1, train_loss, train_acc, val_acc, val_loss))\n",
    "print(\n",
    "    \"Best Epoch {}, final test loss {:.4f}\".format(\n",
    "        best_epoch, best_val_acc\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../models/GATModel_prot.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:01<00:00, 20.96it/s]\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "lab = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "        batch_graphs, batch_labels = batch\n",
    "        batch_graphs = batch_graphs.to(device)\n",
    "        batch_labels = batch_labels.long().to(device)\n",
    "        out = model(batch_graphs, batch_graphs.ndata[\"feature\"].to(dtype=torch.float32))\n",
    "        pred += out.argmax(dim=1).tolist()\n",
    "        lab += batch_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:01<00:00, 21.19it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_test=[]\n",
    "lab_test = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "        batch_graphs, batch_labels = batch\n",
    "        batch_graphs = batch_graphs.to(device)\n",
    "        batch_labels = batch_labels.long().to(device)\n",
    "        out = model(batch_graphs, batch_graphs.ndata[\"feature\"].to(dtype=torch.float32))\n",
    "        out = model.hidden\n",
    "        emb_test += out.tolist()\n",
    "        lab_test += batch_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:06<00:00, 18.42it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_train=[]\n",
    "lab_train = []\n",
    "for batch in tqdm(train_dataloader):\n",
    "        batch_graphs, batch_labels = batch\n",
    "        batch_graphs = batch_graphs.to(device)\n",
    "        batch_labels = batch_labels.long().to(device)\n",
    "        out = model(batch_graphs, batch_graphs.ndata[\"feature\"].to(dtype=torch.float32))\n",
    "        out = model.hidden\n",
    "        emb_train += out.tolist()\n",
    "        lab_train += batch_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(g, emb):\n",
    "    degree = (g.out_degrees().float() + g.in_degrees().float()).numpy()\n",
    "    num_edges = g.number_of_edges()\n",
    "    num_nodes = g.number_of_nodes()\n",
    "    nx_g = g.to_networkx().to_undirected()\n",
    "    laplacian = nx.laplacian_matrix(nx_g).astype(np.float32).toarray()\n",
    "    eigenvals, eigenvecs = np.linalg.eigh(laplacian)\n",
    "    return emb+[np.mean(degree), np.max(degree)/len(degree), 100*num_edges / (num_nodes * (num_nodes - 1))] + list(eigenvals[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_train)):\n",
    "    emb_train[i] = create_features(train_dataset[i][0], emb_train[i])\n",
    "\n",
    "for i in range(len(emb_test)):\n",
    "    emb_test[i] = create_features(test_dataset[i][0], emb_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb =XGBClassifier(random_state=0)\n",
    "\n",
    "xgb.fit(emb_train, lab_train)\n",
    "predxgb = xgb.predict(emb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5761047463175123"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(lab_test, predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
